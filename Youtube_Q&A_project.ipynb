{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#YouTube Video Transcription with Q&A using LLM\n",
        "\n",
        "#### Author: Abhishek Dubey\n",
        "#### Linkedin: https://www.linkedin.com/in/abhishek-dubey96/\n",
        "#### Email: abhishekdb.1996@gmail.com\n",
        "#### Github: https://github.com/Abhiee8322\n",
        "\n"
      ],
      "metadata": {
        "id": "YlD-8RXxjgqK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given list of youtube videos, generate audio transcripts and then using NLP techniques query questions from the generated texts.\n",
        "\n",
        "> Conditions:\n",
        "\n",
        "1. If multiple videos are there, then first filter out videos that were long more than an hour.\n",
        "2. If multiple videos are there then keep the videos only until the cumulative sum of duration of 2 hours is reached.\n",
        "\n",
        "\n",
        "*  Save the embeddings for each video into google drive so that it is reusable.\n",
        "\n"
      ],
      "metadata": {
        "id": "JGuL0pfej_8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Methodology followed:\n",
        "\n",
        "1. Install/Import necessary libraries, modules.\n",
        "2. Function creation of filtering out videos based on length.\n",
        "3. Downloading the audio extracted from the output of the previous step and then storing it in a folder.\n",
        "4. Deleting audio (optional)\n",
        "5. Generated a function to split the input audio into small chunks due to token issue of whisper API and stored the processed audio into the folder.\n",
        "6. Whisper API used to take input from previous step and then generate the transcriptions.\n",
        "7. Document processing begins where recursive splitter is used to split the documents, then chroma is used as a vector db and openai embeddings are used and the resulting vector db is stored in the google drive.\n",
        "8. Extracting the stored vector from the google drive and then querying is performed to get the desired output.\n"
      ],
      "metadata": {
        "id": "d9BFa0ycmqjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## installing necessary modules\n",
        "!pip install yt-dlp\n",
        "!pip install cohere\n",
        "!pip install tiktoken\n",
        "!pip uninstall typing-extensions -y quiet\n",
        "!pip install typing-extensions==4.5.0 --quiet\n",
        "!pip install --upgrade tensorflow-probability\n",
        "!pip install --upgrade --quiet openai\n",
        "!pip install pydub\n",
        "!pip install chromadb --quiet\n",
        "!pip install openai --quiet\n",
        "!pip install langchain --quiet\n",
        "!pip install tiktoken --quiet\n",
        "!pip install docx2txt --quiet\n",
        "!pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEqdXRFKmuqE",
        "outputId": "e8ea29e6-1594-4d15-c49e-20e90601e6ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2023.12.30-py2.py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mutagen (from yt-dlp)\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex (from yt-dlp)\n",
            "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2023.11.17)\n",
            "Requirement already satisfied: requests<3,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.0.7)\n",
            "Collecting websockets>=12.0 (from yt-dlp)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli (from yt-dlp)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.31.0->yt-dlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.31.0->yt-dlp) (3.6)\n",
            "Installing collected packages: brotli, websockets, pycryptodomex, mutagen, yt-dlp\n",
            "Successfully installed brotli-1.1.0 mutagen-1.47.0 pycryptodomex-3.20.0 websockets-12.0 yt-dlp-2023.12.30\n",
            "Collecting cohere\n",
            "  Downloading cohere-4.44-py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (3.9.1)\n",
            "Collecting backoff<3.0,>=2.0 (from cohere)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting fastavro<2.0,>=1.8 (from cohere)\n",
            "  Downloading fastavro-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib_metadata<7.0,>=6.0 (from cohere)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.0.7)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (2023.11.17)\n",
            "Installing collected packages: importlib_metadata, fastavro, backoff, cohere\n",
            "  Attempting uninstall: importlib_metadata\n",
            "    Found existing installation: importlib-metadata 7.0.1\n",
            "    Uninstalling importlib-metadata-7.0.1:\n",
            "      Successfully uninstalled importlib-metadata-7.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 cohere-4.44 fastavro-1.9.3 importlib_metadata-6.11.0\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n",
            "Installing collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.5.2\n",
            "Found existing installation: typing_extensions 4.5.0\n",
            "Uninstalling typing_extensions-4.5.0:\n",
            "  Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[33mWARNING: Skipping quiet as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: tensorflow-probability in /usr/local/lib/python3.10/dist-packages (0.22.0)\n",
            "Collecting tensorflow-probability\n",
            "  Downloading tensorflow_probability-0.23.0-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (1.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (1.23.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (2.2.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (0.5.4)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (0.1.8)\n",
            "Installing collected packages: tensorflow-probability\n",
            "  Attempting uninstall: tensorflow-probability\n",
            "    Found existing installation: tensorflow-probability 0.22.0\n",
            "    Uninstalling tensorflow-probability-0.22.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.22.0\n",
            "Successfully installed tensorflow-probability-0.23.0\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.1/212.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.0/509.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.6/105.6 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.0/798.0 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## importing necessary libraries\n",
        "import os\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import Docx2txtLoader\n",
        "import yt_dlp\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "from datetime import datetime\n",
        "from langchain.schema import Document"
      ],
      "metadata": {
        "id": "hAouw60gYInC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## get your openAI key and then put it here\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))"
      ],
      "metadata": {
        "id": "Ck00qVypZb77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Timing function where any video more than 1 hours is removed from the list and cumulative video length should not be more than 2 hours."
      ],
      "metadata": {
        "id": "-cJ86wzLYq-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_youtube_audio_length(video_urls):\n",
        "    # Configure YouTube downloader options\n",
        "    ydl_opts = {'format': 'bestaudio'}\n",
        "\n",
        "    # Create a YoutubeDL object with the specified options\n",
        "    ydl = yt_dlp.YoutubeDL(ydl_opts)\n",
        "\n",
        "    audio_lengths = []\n",
        "\n",
        "    # Iterate through each video URL\n",
        "    for url in video_urls:\n",
        "        try:\n",
        "            # Extract information about the video without downloading it\n",
        "            info_dict = ydl.extract_info(url, download=False)\n",
        "\n",
        "            # Get the duration of the audio in seconds (default to 0 if not available)\n",
        "            duration = info_dict.get('duration', 0)\n",
        "\n",
        "            # Append the duration to the list\n",
        "            audio_lengths.append(duration)\n",
        "        except yt_dlp.DownloadError as e:\n",
        "            # Handle download errors, if any\n",
        "            print(f\"An error occurred: {e}\")\n",
        "\n",
        "    return audio_lengths\n",
        "\n",
        "def filter_youtube_audio(video_urls):\n",
        "    # Get the durations of the YouTube audio for each video URL\n",
        "    audio_lengths = get_youtube_audio_length(video_urls)\n",
        "\n",
        "    filtered_video_urls = []\n",
        "    total_duration = 0\n",
        "\n",
        "    # Iterate through each video URL and its corresponding duration\n",
        "    for video_url, length in zip(video_urls, audio_lengths):\n",
        "        # Check if adding the current video does not exceed the total duration limit (2 hours)\n",
        "        if total_duration + length <= 7200 and length <= 7200 - total_duration:\n",
        "            filtered_video_urls.append(video_url)\n",
        "            total_duration += length\n",
        "        elif total_duration >= 7200:\n",
        "            # Break the loop if the total duration exceeds the limit\n",
        "            break\n",
        "\n",
        "    return filtered_video_urls\n",
        "\n",
        "# Example usage:\n",
        "video_urls = ['https://www.youtube.com/watch?v=LWebKGrFjcM',\n",
        "              'https://www.youtube.com/watch?v=mW7RSGPK_NU']\n",
        "\n",
        "# Call the function to filter YouTube videos based on duration\n",
        "filtered_videos = filter_youtube_audio(video_urls)\n",
        "\n",
        "# Print the filtered video URLs\n",
        "print(\"Filtered Video URLs:\", filtered_videos)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1dTzQ0goitk",
        "outputId": "f5c32e9c-0035-4d24-9d2b-0427fb3f7d51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=LWebKGrFjcM\n",
            "[youtube] LWebKGrFjcM: Downloading webpage\n",
            "[youtube] LWebKGrFjcM: Downloading ios player API JSON\n",
            "[youtube] LWebKGrFjcM: Downloading android player API JSON\n",
            "[youtube] LWebKGrFjcM: Downloading m3u8 information\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=mW7RSGPK_NU\n",
            "[youtube] mW7RSGPK_NU: Downloading webpage\n",
            "[youtube] mW7RSGPK_NU: Downloading ios player API JSON\n",
            "[youtube] mW7RSGPK_NU: Downloading android player API JSON\n",
            "[youtube] mW7RSGPK_NU: Downloading m3u8 information\n",
            "Filtered Video URLs: ['https://www.youtube.com/watch?v=LWebKGrFjcM', 'https://www.youtube.com/watch?v=mW7RSGPK_NU']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "\n",
        "1.   **get_youtube_audio_length Function:**\n",
        "\n",
        "\n",
        "\n",
        "*   Uses yt_dlp library to create a YouTube downloader object with specified options ('format': 'bestaudio').\n",
        "*  Iterates through a list of video URLs.\n",
        "*  Extracts information about each video without downloading it.\n",
        "*  Retrieves the audio duration (in seconds) from the information and appends it to the audio_lengths list.\n",
        "*  Handles download errors using a try-except block.\n",
        "\n",
        "2. **filter_youtube_audio Function:**\n",
        "\n",
        "* Calls get_youtube_audio_length to get the durations of YouTube audio for each video URL.\n",
        "\n",
        "* Iterates through the video URLs and their corresponding durations.\n",
        "\n",
        "* Filters videos based on their duration to ensure that the total duration does not exceed 2 hours (7200 seconds).\n",
        "\n",
        "* Appends valid video URLs to the filtered_video_urls list.\n",
        "\n",
        "* Breaks the loop if the total duration exceeds the limit.\n"
      ],
      "metadata": {
        "id": "H75POkniolnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Audio download** happens and input_folder is created where the audio downloaded is stored and audio is named according to the youtube video name."
      ],
      "metadata": {
        "id": "YelQucnlY96w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_audio(youtube_url, output_folder='audio'):\n",
        "    try:\n",
        "        # Create the input folder if it doesn't exist\n",
        "        os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "        # Specify the options for downloading audio\n",
        "        options = {\n",
        "            'format': 'bestaudio/best',\n",
        "            'postprocessors': [{\n",
        "                'key': 'FFmpegExtractAudio',\n",
        "                'preferredcodec': 'mp3',\n",
        "                'preferredquality': '192',\n",
        "            }],\n",
        "            'outtmpl': os.path.join(output_folder, f'%(title)s.%(ext)s'),\n",
        "        }\n",
        "\n",
        "        # Create a yt_dlp object with the specified options\n",
        "        ydl = yt_dlp.YoutubeDL(options)\n",
        "\n",
        "        # Download the audio\n",
        "        with ydl:\n",
        "            result = ydl.extract_info(youtube_url, download=True)\n",
        "\n",
        "        print(f\"Audio for {youtube_url} downloaded successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "# Example usage:\n",
        "filtered_videos = ['https://www.youtube.com/watch?v=LWebKGrFjcM', 'https://www.youtube.com/watch?v=mW7RSGPK_NU']\n",
        "input_folder = 'input_folder'\n",
        "\n",
        "# Download audio for each video and store in the input folder\n",
        "for video_url in filtered_videos:\n",
        "    download_audio(video_url, input_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GjffBLRz58B",
        "outputId": "5248297d-a203-4cc2-90b9-48e745e9eaab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=LWebKGrFjcM\n",
            "[youtube] LWebKGrFjcM: Downloading webpage\n",
            "[youtube] LWebKGrFjcM: Downloading ios player API JSON\n",
            "[youtube] LWebKGrFjcM: Downloading android player API JSON\n",
            "[youtube] LWebKGrFjcM: Downloading m3u8 information\n",
            "[info] LWebKGrFjcM: Downloading 1 format(s): 251\n",
            "[download] Destination: input_folder/Eliezer Yudkowsky response to Sam Altman ｜ Lex Fridman Podcast Clips.webm\n",
            "[download] 100% of   13.45MiB in 00:00:00 at 46.33MiB/s  \n",
            "[ExtractAudio] Destination: input_folder/Eliezer Yudkowsky response to Sam Altman ｜ Lex Fridman Podcast Clips.mp3\n",
            "Deleting original file input_folder/Eliezer Yudkowsky response to Sam Altman ｜ Lex Fridman Podcast Clips.webm (pass -k to keep)\n",
            "Audio for https://www.youtube.com/watch?v=LWebKGrFjcM downloaded successfully!\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=mW7RSGPK_NU\n",
            "[youtube] mW7RSGPK_NU: Downloading webpage\n",
            "[youtube] mW7RSGPK_NU: Downloading ios player API JSON\n",
            "[youtube] mW7RSGPK_NU: Downloading android player API JSON\n",
            "[youtube] mW7RSGPK_NU: Downloading m3u8 information\n",
            "[info] mW7RSGPK_NU: Downloading 1 format(s): 251\n",
            "[download] Destination: input_folder/Sam Altman disagreement with Eliezer Yudkowsky ｜ Lex Fridman Podcast Clips.webm\n",
            "[download] 100% of    3.54MiB in 00:00:00 at 32.02MiB/s  \n",
            "[ExtractAudio] Destination: input_folder/Sam Altman disagreement with Eliezer Yudkowsky ｜ Lex Fridman Podcast Clips.mp3\n",
            "Deleting original file input_folder/Sam Altman disagreement with Eliezer Yudkowsky ｜ Lex Fridman Podcast Clips.webm (pass -k to keep)\n",
            "Audio for https://www.youtube.com/watch?v=mW7RSGPK_NU downloaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "\n",
        "**download_audio Function:**\n",
        "\n",
        "*   Creates the output folder (default is 'audio') if it doesn't exist using os.makedirs.\n",
        "*   Specifies options for downloading audio using the yt_dlp library. The options include the desired audio format (mp3), codec, and quality.\n",
        "* Creates a yt_dlp object with the specified options.\n",
        "* Downloads the audio from the provided YouTube URL and saves it to the input folder.\n",
        "* Prints a success message if the download is successful, or an error message if an exception occurs.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pYPDHhWbqr99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_audio(audio_filename, input_folder='input_audio'):\n",
        "    try:\n",
        "        # Construct the full path to the audio file\n",
        "        audio_path = os.path.join(input_folder, audio_filename)\n",
        "\n",
        "        # Check if the file exists before attempting to delete\n",
        "        if os.path.exists(audio_path):\n",
        "            os.remove(audio_path)\n",
        "            print(f\"Audio file '{audio_filename}' deleted successfully.\")\n",
        "        else:\n",
        "            print(f\"Audio file '{audio_filename}' does not exist.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "# Example usage:\n",
        "# Assuming you want to delete a file named 'example_audio.mp3' from the 'input_audio' folder\n",
        "delete_audio('/content/input_folder/Eliezer Yudkowsky response to Sam Altman ｜ Lex Fridman Podcast Clips.mp3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3w3JtC2ZV7_",
        "outputId": "2eeef0cc-d27d-4270-c5f6-adb6a7f75c80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio file '/content/input_folder/Eliezer Yudkowsky response to Sam Altman ｜ Lex Fridman Podcast Clips.mp3' deleted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One issue encountered that the **input audio** must be **broken down** into **smaller chunks** so that the input to the OpenAI whisper API is short, because if longer audio is provided excess token issue comes, so here the input audio is broken into 3 min chunks and are in sequence, so that transcribed text has its meaning intact. Also the output of the function is stored in the output_folder. Here **pydub library** is used to split the input audio into chunks."
      ],
      "metadata": {
        "id": "9ATc3SZDaDzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def break_audio_into_chunks(input_folder, output_folder, chunk_size_minutes=3):\n",
        "    # Create input and output folders if they don't exist\n",
        "    os.makedirs(input_folder, exist_ok=True)\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(\".mp3\"):\n",
        "            input_path = os.path.join(input_folder, filename)\n",
        "\n",
        "            # Load the audio file using pydub\n",
        "            song = AudioSegment.from_mp3(input_path)\n",
        "\n",
        "            # Calculate the chunk size in milliseconds\n",
        "            chunk_size_ms = chunk_size_minutes * 60 * 1000\n",
        "\n",
        "            # Split the audio into chunks\n",
        "            chunks = [song[i:i + chunk_size_ms] for i in range(0, len(song), chunk_size_ms)]\n",
        "\n",
        "            # Export each chunk to the output folder with a unique identifier\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "            for i, chunk in enumerate(chunks):\n",
        "                output_identifier = f\"{timestamp}_chunk_{i + 1}\"\n",
        "                output_path = os.path.join(output_folder, f\"{os.path.splitext(filename)[0]}_{output_identifier}.mp3\")\n",
        "                chunk.export(output_path, format=\"mp3\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_folder = \"/content/input_folder\"\n",
        "    output_folder = \"/content/output_folder\"\n",
        "\n",
        "    break_audio_into_chunks(input_folder, output_folder)\n"
      ],
      "metadata": {
        "id": "xfGl3tYeZ3tQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "\n",
        "break_audio_into_chunks Function:\n",
        "\n",
        "\n",
        "\n",
        "*   Creates input and output folders if they don't exist using os.makedirs.\n",
        "*   Iterates through the files in the input folder (assumed to be mp3 files).\n",
        "*   Loads each audio file using pydub.\n",
        "*   Calculates the chunk size in milliseconds based on the specified duration.\n",
        "*   Splits the audio file into chunks using list comprehension.\n",
        "*   Exports each chunk to the output folder with a unique identifier based on the current timestamp and chunk index.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xt6ryLAIsRlU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transcription begins and takes input from the output_folder and then stores it in the list transcriptions"
      ],
      "metadata": {
        "id": "Csnk8RT5a6u2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_transcripts(api_key, input_folder):\n",
        "    # Initialize the OpenAI client with your API key\n",
        "    client = OpenAI(api_key=api_key)\n",
        "\n",
        "    transcriptions = []  # List to store transcriptions\n",
        "\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(\".mp3\"):\n",
        "            input_path = os.path.join(input_folder, filename)\n",
        "\n",
        "            # Open the audio file\n",
        "            with open(input_path, \"rb\") as audio_file:\n",
        "                # Create transcription for the audio file\n",
        "                transcript = client.audio.transcriptions.create(\n",
        "                    model=\"whisper-1\",\n",
        "                    file=audio_file,\n",
        "                    response_format=\"text\"\n",
        "                )\n",
        "\n",
        "                # Append the transcription to the list\n",
        "                transcriptions.append(transcript)\n",
        "\n",
        "    return transcriptions\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    api_key = userdata.get('OPENAI_API_KEY')\n",
        "    output_folder = \"/content/output_folder\"  # Replace with the path to your output folder\n",
        "\n",
        "    transcriptions = generate_transcripts(api_key, output_folder)\n",
        "\n",
        "    # Now 'transcriptions' contains a list of transcriptions that can be accessed\n",
        "    print(transcriptions)\n",
        "\n",
        "all_transcriptions = '\\n'.join(transcriptions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGGdhCo2a2LS",
        "outputId": "0bb565e9-b404-4acd-a6d5-1c8afd18bd49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"There is some aspect, and I'm torn here, because it's difficult to reason about the exponential improvement of technology. But also, I've seen time and time again how transparent and iterative trying out, as you improve the technology, trying it out, releasing it, testing it, how that can improve your understanding of the technology. Such that the philosophy of how to do, for example, safety of any kind of technology, but AI safety, gets adjusted over time, rapidly. A lot of the formative AI safety work was done before people even believed in deep learning, and certainly before people believed in large language models. And I don't think it's updated enough, given everything we've learned now, and everything we will learn going forward. So I think it's gotta be this very tight feedback loop. I think the theory does play a real role, of course, but continuing to learn what we learn from how the technology trajectory goes, is quite important. I think now is a very good time, and we're trying to figure out how to do this, to significantly ramp up technical alignment work. I think we have new tools, we have new understanding, and there's a lot of work that's important to do, that we can do now. Thank you.\\n\", \"The increase in quality of life that AI can deliver is extraordinary. We can make the world amazing, and we can make people's lives amazing. We can cure diseases. We can increase material wealth. We can help people be happier, more fulfilled, all of these sorts of things. And then people are like, oh, well, no one is gonna work. But people want status. People want drama. People want new things. People want to create. People want to feel useful. People want to do all these things, and we're just gonna find new and different ways to do them, even in a vastly better, unimaginably good standard of living world. But that world, the positive trajectories with AI, that world is with an AI that's aligned with humans and doesn't hurt, doesn't limit, doesn't try to get rid of humans. And there's some folks who consider all the different problems with a super-intelligent AI system. So one of them is Eliezer Yudkowsky. He warns that AI will likely kill all humans. And there's a bunch of different cases, but I think one way to summarize it is that it's almost impossible to keep AI aligned as it becomes super-intelligent. Can you steel man the case for that? And to what degree do you disagree with that trajectory? So first of all, I will say, I think that there's some chance of that, and it's really important to acknowledge it, because if we don't talk about it, if we don't treat it as potentially real, we won't put enough effort into solving it. And I think we do have to discover new techniques to be able to solve it. I think a lot of the predictions, this is true for any new field, but a lot of the predictions about AI in terms of capabilities, in terms of what the safety challenges and the easy parts are going to be, have turned out to be wrong. The only way I know how to solve a problem like this is iterating our way through it, learning early, and limiting the number of one-shot-to-get-it-right scenarios that we have. To Steel Man, well, I can't just pick one AI safety case or AI alignment case, but I think Eliezer wrote a really great blog post. I think some of his work has been sort of somewhat difficult to follow or had what I view as quite significant logical flaws, but he wrote this one blog post outlining why he believed that alignment was such a hard problem that I thought was, again, don't agree with a lot of it, but well-reasoned and thoughtful and very worth reading. So I think I'd point people to that as the Steel Man. Yeah, and I'll also have a conversation with him.\\n\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "\n",
        "**generate_transcripts Function:**\n",
        "\n",
        "\n",
        "* Initializes the OpenAI client with the provided API key.\n",
        "* Iterates through the files in the input folder (assumed to be mp3 files).\n",
        "* Opens each audio file and creates a transcription using the Whisper ASR model through the OpenAI API.\n",
        "*Appends each transcription to the transcriptions list.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9rB6r0iutpO_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The provided code defines a function **process_documents** that takes a list of transcriptions, an OpenAI API key, and a persist directory as input. It processes the transcriptions by creating documents, splitting them into texts, generating embeddings, and finally, creating a Chroma instance with the given parameters."
      ],
      "metadata": {
        "id": "J7I178mkuPcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_documents(all_transcriptions, api_key, persist_directory):\n",
        "\n",
        "\n",
        "    # Split documents into texts using RecursiveCharacterTextSplitter\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=0)\n",
        "    texts = text_splitter.split_text(all_transcriptions)\n",
        "\n",
        "    # Generate embeddings using OpenAI API\n",
        "    embeddings = OpenAIEmbeddings(api_key=api_key)\n",
        "\n",
        "    # Create Chroma instance from texts, embeddings, and persist_directory\n",
        "    docsearch = Chroma.from_texts(texts, embeddings, persist_directory=persist_directory)\n",
        "\n",
        "    return docsearch\n",
        "\n",
        "# Example usage:\n",
        "# Assuming 'all_transcriptions' is a list of transcriptions and 'userdata' contains the OpenAI API key\n",
        "all_transcriptions = all_transcriptions\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "persist_directory = 'your drive folder link'\n",
        "\n",
        "# Call the function to process documents\n",
        "result = process_documents(all_transcriptions, api_key, persist_directory)\n"
      ],
      "metadata": {
        "id": "SHtHQ7M5uVc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "\n",
        "**process_documents Function:**\n",
        "\n",
        "* Takes a list of transcriptions, an OpenAI API key, and a persist directory as input.\n",
        "* Creates documents from the transcriptions using the Document class from langchain.schema.\n",
        "* Splits the documents into texts using **RecursiveCharacterTextSplitter** from langchain.text_splitter.\n",
        "* Generates embeddings using OpenAIEmbeddings from langchain.embeddings.\n",
        "* Creates a Chroma instance using Chroma.from_documents with the processed texts, embeddings, and persist directory."
      ],
      "metadata": {
        "id": "a-x-lzA2ueoc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following function vector is retrieved from google drive and then input with the embedding to return the query instance."
      ],
      "metadata": {
        "id": "z94onqhrv6dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_chroma_and_qa(persist_directory, api_key):\n",
        "    # Load vectors from the drive\n",
        "    db3 = Chroma(persist_directory=persist_directory, embedding_function=OpenAIEmbeddings(api_key=api_key))\n",
        "\n",
        "    # Create RetrievalQA instance\n",
        "    qa = RetrievalQA.from_chain_type(llm=OpenAI(api_key=api_key,model_name='gpt-3.5-turbo-instruct'),\n",
        "                                     chain_type=\"stuff\", retriever=db3.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":2}) )\n",
        "\n",
        "\n",
        "    return db3, qa\n",
        "\n",
        "# Example usage:\n",
        "persist_directory = 'drive link'\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "db3, qa = create_chroma_and_qa(persist_directory, api_key)\n"
      ],
      "metadata": {
        "id": "R6TGHQM3c-Ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "\n",
        "**create_chroma_and_qa Function:**\n",
        "\n",
        "* Creates a Chroma instance (db3) using the specified persist_directory and an OpenAIEmbeddings instance as the embedding function.\n",
        "* Creates a RetrievalQA instance (qa) using an OpenAI language model (OpenAI(api_key=api_key, model_name='gpt-3.5-turbo-instruct')), specifying the chain type as \"stuff,\" and setting the retriever to the previously created Chroma instance."
      ],
      "metadata": {
        "id": "6hf1mDuzwIer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What Eliezer Yudkowsky thinks about AI safety?\"\n",
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "HHVCgcawdMve",
        "outputId": "858a289a-a5b5-4e1d-8e49-38ac7017b41d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Eliezer Yudkowsky believes that AI safety is a major concern and warns that as AI becomes super-intelligent, it may become impossible for humans to keep it aligned and prevent it from harming humans. \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Tey66f-aLIj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}